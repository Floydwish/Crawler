#  读书笔记

# 宽度优先搜索策略
原因：（1）深度优先遍历可能会在深度上过“深”而陷入“黑洞”；    
      （2）重要的网页往往距离种子网页比较近，越深的网页的重要性越低；   
      （3）万维网深度最多17层，但到达某面总存在一条很短的路径，宽度优先遍历会以最快的速度达到这个网页；  
      （4）宽度优先遍历有利于多爬虫的合作抓取，多爬虫合作通常先抓取站内链接，抓取的封闭性很强；
      
      
# 解析HTML网页---Jsoup
Maven中配置：   
      <dependency>   
         <groupId>org.jsoup</gorup>   
         <artifactId>jsoup</artifactId>   
         <version>1.10.3</version>   
      </dependency>   
      
      
# 解析Json数据---Json
Maven中配置：   
      <dependency>   
         <groupId>com.alibabap</gorup>   
         <artifactId>fastjson</artifactId>   
         <version>1.2.35.3</version>   
      </dependency>   


# 评估页面的重要程度
1.链接的欢迎程度---反向链接（即指向当前URL的链接）的数量和质量决定的，定义为IB(P)；   
2.链接的重要程度---关于URL字符串的函数，仅仅考察字符串本身，比如认为".com"和"home"的URL比".cc"和"map"高，定义为IL(P)；   
3.平均链接的深度---根据上面所分析的宽度优先的原则，计算全站的平均链接深度，然后认为距离种子站点越近的重要性越高，定义为ID(P)；   

则网页的重要性I(P)=X*IB(P)+Y*IL(P)，ID(P)由宽度优先遍历规则保证   


# 存储
1、Berkeley DB， 内存数据库，内存数据结构并不适合大规模爬虫的应用
   （1）底层实现B树；   
   （2）key/value结构；  
   （3）布隆过滤器；      
2、Heritrix，成熟的开源爬虫软件    
   （1）封闭Berkeley DB，存放所有待处理的链接，过滤已被抓取的连接(BdbUriUniFilter)；   
   （2） 模块化的设计，各模块由CrawlController类协调，负责整个爬虫任务的开始的结束；  


# 爬虫队列
保存爬下来的URL，具备以下几个特点：  
1.能够存储海量数据，当内存容量不够时可以固化在硬盘；     
2.快速存取数据；  
3.支持多线程访问；  

因此采用Hash存储，一般选取URL作为key值，选取MD5压缩算法  


# 爬虫架构
一、应该满足的条件
1.分布式  
2.可伸缩性：能通过增加额外的机器和带宽提高抓取速度  
3.性能和有效性：有效使用系统资源，如CPU、网络带宽、和存储空间  
4.质量：针对大部分网络不能及时出现在用户查询中，所以应该首先抓取重要网页  
5.新鲜性：持续运行  
6.更新：爬虫应该取得已获取网页的新的拷贝，例如网站的回贴功能  
7.可扩展性：为了能够支持新的数据格式和新的抓取协议，爬虫应该设计成模块化的形式  

二、实现异步I/O的框架
1.Mina---借由Java的NIO的反应式实现的模拟前摄式模型；  
2.Grizzly---Web服务器GlassFish的I/O核心；  
3.Netty---NIO客户端服务器框架；  
4.Naga---把普通的Socket和ServerSocket封装成支持NIO的形式；  


# 一致性Hash（Consistent Hash） ---解决因特网中的热点（Hot Spot）问题
1.单调性 --- 如果已经有内容通过哈希分配到了相应的缓存中，而又有新的缓冲加入到系统，哈希的结果应该能够保证原有已分配的内容可以被映射到新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区   
2.平衡性 --- 哈希的结果能够尽可能分布到所有缓冲中去，这样使得所有的缓冲空间都得到利用   
3.分散性 --- 不同终端将相同内容映射到不同缓冲中去，好的哈希算法应该能够尽量避免这种不一致的情况发生  
4.负载 --- （从另一个角度看待分散性问题）对特定的缓冲区，也可能被不同用户映射为不同的内容




